{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Building Blocks for Digital Agents Research New to agents? See our Intro to UI Agents . We take you through the installation and running your first agent step-by-step. Why OpenApps? Evaluate and train multimodal agents to use apps like humans do (by clicking, typing, and scrolling): \u2705 Unlimited data (for evaluating and training UI-agents): Configurable state and design to generate thousands of versions of each app \u2705 Lightweight : runs on a single CPU (and Python-based); no Docker or OS emulators needed \u2705 Ground truth rewards : task rewards are based on the underlying state and all app logic is transparent in Python Install Install the conda alternative uv and clone the repo: git clone https://github.com/facebookresearch/OpenApps.git Install dependencies: uv sync For other installation options and online shop setup see Installation . Run OpenApps uv run launch.py App variations Each app can be modified with variables available in config/apps . You can override any of these via command line: uv run launch.py 'apps.todo.init_todos=[[\"Call Mom\", false]]' OpenApps also comes with pre-defined variations that can affect the content and appearance of apps. Appearance challenging font export APPEARANCE = challenging_font dark theme export APPEARANCE = dark_theme default export APPEARANCE = default Launch specific apps with selected appearance: uv run launch.py apps/start_page/appearance = $APPEARANCE Or specific apps with: apps/calendar/appearance=$APPEARANCE . Content german export CONTENT = german long_descriptions export CONTENT = long_descriptions pop-up uv run launch.py apps/pop_ups = adversarial_descriptions uv run launch.py apps/start_page/content = $CONTENT Or specific apps with: apps/calendar/content=$CONTENT . You can see the specific variables for each defined in the individual apps. For example, config/apps/maps/appearance/dark_theme.yaml . Launch Agent For agents to directly interact with apps, install: playwright install chromium . Launch an agent to perform a task of adding a meeting with Dennis to the calendar : Random Click Agent uv run launch_agent.py agent = dummy task_name = add_meeting_with_dennis GPT-5.1 Agent # export OPENAI_API_KEY=\"\" uv run launch_agent.py agent = GPT-5-1 task_name = add_meeting_with_dennis You can specify the agent of your choice with the agent= argument. For example agent=dummy is a simple agent that clicks randomly on any buttons, great for exploration! Learn more about launching with OpenAI, Claude, VLLM models, or specialized models such as UI-Tars in agents guide and available tasks in our task guide . Note: To test the ability of a model to navigate the UI without simplified HTML, set: agent.use_axtree=False To see the agent solving the task live: uv run launch_agent.py browsergym_env_args.headless=False Logs By default, information about the number of steps an agent took, task success, etc. will be shown in the terminal: ... Experiment results exp_dir: /Users/m... n_steps: 10 cum_reward: 0.0 stats.cum_agent_elapsed: 0.0017838478088378906 stats.max_agent_elapsed: 0.0002570152282714844 ... All logs are stored log_outputs will contain information about each run You can also enable logging to weights and biases by logging into your account and setting the flag: use_wandb=True . Launch Agent(s) Across Multiple Tasks launch thousands of app variations to study agent behaviors in parallel coming soon! Testing Run all tests via: uv run - m pytest tests / Attribution Our apps are built on top of several excellent frameworks: FastHTML framework and examples which allowed us to build fully functional apps in Python, the language most familiar to AI researchers. Browser Gym and AgentLab : Spacy : for natural language processing Open Street Maps : for our Maps apps. (and for the optional webshop) we rely on WebShop developed by Princeton University Some icons are have been designed using resources from Flaticon.com Our work is licensed under CC-BY-NC, please refer to the LICENSE file in the top level directory. Copyright \u00a9 Meta Platforms, Inc. See the Terms of Use and Privacy Policy for this project.","title":"Start"},{"location":"#install","text":"Install the conda alternative uv and clone the repo: git clone https://github.com/facebookresearch/OpenApps.git Install dependencies: uv sync For other installation options and online shop setup see Installation .","title":"Install"},{"location":"#run-openapps","text":"uv run launch.py","title":"Run OpenApps"},{"location":"#app-variations","text":"Each app can be modified with variables available in config/apps . You can override any of these via command line: uv run launch.py 'apps.todo.init_todos=[[\"Call Mom\", false]]' OpenApps also comes with pre-defined variations that can affect the content and appearance of apps.","title":"App variations"},{"location":"#appearance","text":"challenging font export APPEARANCE = challenging_font dark theme export APPEARANCE = dark_theme default export APPEARANCE = default Launch specific apps with selected appearance: uv run launch.py apps/start_page/appearance = $APPEARANCE Or specific apps with: apps/calendar/appearance=$APPEARANCE .","title":"Appearance"},{"location":"#content","text":"german export CONTENT = german long_descriptions export CONTENT = long_descriptions pop-up uv run launch.py apps/pop_ups = adversarial_descriptions uv run launch.py apps/start_page/content = $CONTENT Or specific apps with: apps/calendar/content=$CONTENT . You can see the specific variables for each defined in the individual apps. For example, config/apps/maps/appearance/dark_theme.yaml .","title":"Content"},{"location":"#launch-agent","text":"For agents to directly interact with apps, install: playwright install chromium . Launch an agent to perform a task of adding a meeting with Dennis to the calendar : Random Click Agent uv run launch_agent.py agent = dummy task_name = add_meeting_with_dennis GPT-5.1 Agent # export OPENAI_API_KEY=\"\" uv run launch_agent.py agent = GPT-5-1 task_name = add_meeting_with_dennis You can specify the agent of your choice with the agent= argument. For example agent=dummy is a simple agent that clicks randomly on any buttons, great for exploration! Learn more about launching with OpenAI, Claude, VLLM models, or specialized models such as UI-Tars in agents guide and available tasks in our task guide . Note: To test the ability of a model to navigate the UI without simplified HTML, set: agent.use_axtree=False To see the agent solving the task live: uv run launch_agent.py browsergym_env_args.headless=False","title":"Launch Agent"},{"location":"#logs","text":"By default, information about the number of steps an agent took, task success, etc. will be shown in the terminal: ... Experiment results exp_dir: /Users/m... n_steps: 10 cum_reward: 0.0 stats.cum_agent_elapsed: 0.0017838478088378906 stats.max_agent_elapsed: 0.0002570152282714844 ... All logs are stored log_outputs will contain information about each run You can also enable logging to weights and biases by logging into your account and setting the flag: use_wandb=True .","title":"Logs"},{"location":"#launch-agents-across-multiple-tasks","text":"launch thousands of app variations to study agent behaviors in parallel coming soon!","title":"Launch Agent(s) Across Multiple Tasks"},{"location":"#testing","text":"Run all tests via: uv run - m pytest tests /","title":"Testing"},{"location":"#attribution","text":"Our apps are built on top of several excellent frameworks: FastHTML framework and examples which allowed us to build fully functional apps in Python, the language most familiar to AI researchers. Browser Gym and AgentLab : Spacy : for natural language processing Open Street Maps : for our Maps apps. (and for the optional webshop) we rely on WebShop developed by Princeton University Some icons are have been designed using resources from Flaticon.com Our work is licensed under CC-BY-NC, please refer to the LICENSE file in the top level directory. Copyright \u00a9 Meta Platforms, Inc. See the Terms of Use and Privacy Policy for this project.","title":"Attribution"},{"location":"Intro%20to%20UI%20Agents/","text":"Learn how to set up OpenApps, run a GPT-5 agent and make changes to the envrionment.","title":"Intro to UI Agents"},{"location":"agents/","text":"Quickstart: Getting Your Agent to Run Prerequisites To use GPT-5-1 to complete tasks, set your OpenAI API key: export OPENAI_API_KEY = YOUR_KEY Alternatively, edit the corresponding line in config/agent/GPT-5-1.yaml . Supported Clients We support multiple client types: vLLM OpenAI Azure AWS To use a different client, change the client_type argument in your configuration. Check out /src/open_apps/agent/vLLM_agent.py Line 49 and following for specifics about how these clients are called internally. Running Your Agent uv run launch_agent.py agent = GPT-4o To run a local model with vLLM , Launch your local vLLM model: vllm serve [MODEL_NAME] . VLLM will tell you your hostname. Launch your agent uv run launch_agent.py agent = AGENT_CONFIG agent.hostname = VLLM_HOSTNAME Configuring Your Policy Our agent policies are built on top of AgentLab . Our setup enables automatic configuration of your prompt with config flags. Here are some key flags you can configure in your agent's YAML file: Observation Flags: use_axtree : Enable AXTree observation (accessibility tree) use_screenshot : Enable screenshot observation use_som : Add visual marks to screenshots for element identification extract_coords : Include element coordinates in observations History & Memory Flags: use_history : Enable action/thought history tracking use_action_history : Track previous actions taken by the agent use_think_history : Track previous thoughts/reasoning steps Reasoning & Examples Flags: use_thinking : Enable chain-of-thought reasoning before actions use_concrete_example : Include concrete examples in the prompt use_abstract_example : Include abstract reasoning examples in the prompt Custom Prompts: prompt_txt.system_prompt : Override the default system prompt prompt_txt.action_prompt : Define custom action instructions prompt_txt.think_prompt : Define custom thinking/reasoning instructions For the complete set of configuration options, see config/agent/default.yaml . Creating Your Own Agent If AgentLab's capabilities don't meet your needs, you can create a custom agent. Navigate to src/open_apps/agent/ Copy and modify the following files: vLLM_agent.py vLLM_prompt.py This allows you to build rich, custom agent implementations tailored to your specific requirements.","title":"Agents"},{"location":"agents/#quickstart-getting-your-agent-to-run","text":"","title":"Quickstart: Getting Your Agent to Run"},{"location":"agents/#prerequisites","text":"To use GPT-5-1 to complete tasks, set your OpenAI API key: export OPENAI_API_KEY = YOUR_KEY Alternatively, edit the corresponding line in config/agent/GPT-5-1.yaml .","title":"Prerequisites"},{"location":"agents/#supported-clients","text":"We support multiple client types: vLLM OpenAI Azure AWS To use a different client, change the client_type argument in your configuration. Check out /src/open_apps/agent/vLLM_agent.py Line 49 and following for specifics about how these clients are called internally.","title":"Supported Clients"},{"location":"agents/#running-your-agent","text":"uv run launch_agent.py agent = GPT-4o To run a local model with vLLM , Launch your local vLLM model: vllm serve [MODEL_NAME] . VLLM will tell you your hostname. Launch your agent uv run launch_agent.py agent = AGENT_CONFIG agent.hostname = VLLM_HOSTNAME","title":"Running Your Agent"},{"location":"agents/#configuring-your-policy","text":"Our agent policies are built on top of AgentLab . Our setup enables automatic configuration of your prompt with config flags. Here are some key flags you can configure in your agent's YAML file: Observation Flags: use_axtree : Enable AXTree observation (accessibility tree) use_screenshot : Enable screenshot observation use_som : Add visual marks to screenshots for element identification extract_coords : Include element coordinates in observations History & Memory Flags: use_history : Enable action/thought history tracking use_action_history : Track previous actions taken by the agent use_think_history : Track previous thoughts/reasoning steps Reasoning & Examples Flags: use_thinking : Enable chain-of-thought reasoning before actions use_concrete_example : Include concrete examples in the prompt use_abstract_example : Include abstract reasoning examples in the prompt Custom Prompts: prompt_txt.system_prompt : Override the default system prompt prompt_txt.action_prompt : Define custom action instructions prompt_txt.think_prompt : Define custom thinking/reasoning instructions For the complete set of configuration options, see config/agent/default.yaml .","title":"Configuring Your Policy"},{"location":"agents/#creating-your-own-agent","text":"If AgentLab's capabilities don't meet your needs, you can create a custom agent. Navigate to src/open_apps/agent/ Copy and modify the following files: vLLM_agent.py vLLM_prompt.py This allows you to build rich, custom agent implementations tailored to your specific requirements.","title":"Creating Your Own Agent"},{"location":"installation/","text":"Pre-requisite: install uv (a much faster pip): pip install uv (or from source ) 0) Clone repo 1) Install packages: uv sync 2) Activate environment: source .venv/bin/activate 3) Install playwright install chromium Optionally install for onlineshop (off by default) Onlineshop java + spacy configuration 4) Prepare Java, Webshop data and spacy model: chmod +x setup.sh and ./setup.sh for Linux X64 or Mac ARM64 systems 5) Designate Java path: source setup_javapath.sh for Linux X64 or Mac ARM64 systems 6) Check java -version gives you java version \"21.0.1\" 7) Build search engine indexes: chmod +x setup_pyserini.sh and ./setup_pyserini.sh Congratulations! The onlineshop is ready to be used. Remember in future, always run source setup_javapath.sh to configure Java path before launching onlineshop-related tasks. Finally, launch with uv run launch.py apps.onlineshop.enable=True","title":"Manual Installation"},{"location":"tasks/","text":"To ask GPT-4o to mark water plants as done in your todo list: # export OPENAI_API_KEY=\"\" uv run launch_agent.py agent = GPT-5-1 task_name = mark_water_plants_as_done task_name specifies the task. Tasks are defined in config/tasks/all_tasks.yaml . For example, mark_water_plants_as_done : # Indicates class where reward logic is defined _target_ : open_apps.tasks.tasks.MarkToDoDoneTask goal : Mark 'Water plants' as done in my todo list. todo_name : \"Water plants\" Adding New Tasks To add a new task using an existing reward function, simply add a new entry to the config/tasks/all_tasks.yaml : add_my_special_item_to_todo : # _target_ defines the class containing the task reward logic _target_ : open_apps.tasks.tasks.AddToDoTask goal : ENTER YOUR GOAL todo_name : ENTER TITLE of TODO is_done : false You can select this new task by specifying the task_name=add_my_special_item_todo . New custom tasks To add a custom task with its own reward logic, create a new class in src/open_apps/tasks/tasks.py . Your new class should inherit Task and implement a reward function, check_if_task_is_complete , indicating whether the task is complete: @dataclass class MyCustomTask ( Task ): def check_if_task_is_complete ( self , initiate_state : dict , current_state : dict ) -> bool : # we handle providing the initial and current states for you! # write your custom reward logic ... Then create a corresponding entry in config/tasks/all_tasks.yaml : my_custom_task : _target_ : open_apps.tasks.tasks.MyCustomTask goal : ENTER Finally, ask your agent to solve the task by specifying task_name=my_custom_task .","title":"Tasks"},{"location":"tasks/#adding-new-tasks","text":"To add a new task using an existing reward function, simply add a new entry to the config/tasks/all_tasks.yaml : add_my_special_item_to_todo : # _target_ defines the class containing the task reward logic _target_ : open_apps.tasks.tasks.AddToDoTask goal : ENTER YOUR GOAL todo_name : ENTER TITLE of TODO is_done : false You can select this new task by specifying the task_name=add_my_special_item_todo .","title":"Adding New Tasks"},{"location":"tasks/#new-custom-tasks","text":"To add a custom task with its own reward logic, create a new class in src/open_apps/tasks/tasks.py . Your new class should inherit Task and implement a reward function, check_if_task_is_complete , indicating whether the task is complete: @dataclass class MyCustomTask ( Task ): def check_if_task_is_complete ( self , initiate_state : dict , current_state : dict ) -> bool : # we handle providing the initial and current states for you! # write your custom reward logic ... Then create a corresponding entry in config/tasks/all_tasks.yaml : my_custom_task : _target_ : open_apps.tasks.tasks.MyCustomTask goal : ENTER Finally, ask your agent to solve the task by specifying task_name=my_custom_task .","title":"New custom tasks"}]}